
import { supabase } from '@/integrations/supabase/client';
import { v4 as uuidv4 } from 'uuid';

/**
 * Upload a base64 image to Supabase Storage
 */
export const uploadReportImage = async (
  dataUrl: string,
  reportId: string,
  roomId: string
): Promise<string> => {
  try {
    console.log("ğŸ”„ Starting image upload to storage for report:", reportId, "room:", roomId);
    
    // Convert data URL to blob
    const res = await fetch(dataUrl);
    const blob = await res.blob();
    console.log("ğŸ“¦ Image converted to blob, size:", blob.size, "type:", blob.type);
    
    // Generate a unique filename with property and room folder structure
    const fileExt = dataUrl.substring(dataUrl.indexOf('/') + 1, dataUrl.indexOf(';base64'));
    const fileName = `${reportId}/${roomId}/${uuidv4()}.${fileExt || 'jpg'}`;
    
    console.log("ğŸ“‚ Upload path:", fileName);
    
    // Upload to Supabase Storage
    const { data, error } = await supabase.storage
      .from('inspection-images')
      .upload(fileName, blob, {
        contentType: blob.type,
        cacheControl: '3600',
        upsert: false
      });
    
    if (error) {
      console.error("âŒ Storage upload error:", error);
      throw error;
    }
    
    console.log("âœ… File uploaded successfully:", data.path);
    
    // Get the public URL
    const { data: publicUrlData } = supabase.storage
      .from('inspection-images')
      .getPublicUrl(data.path);
    
    console.log("ğŸ”— Public URL generated:", publicUrlData.publicUrl);
    
    return publicUrlData.publicUrl;
  } catch (error) {
    console.error("âŒ Critical error in uploadReportImage:", error);
    throw error; // Don't return fallback, let caller handle the error
  }
};

/**
 * Delete an image from Supabase Storage
 */
export const deleteReportImage = async (imageUrl: string): Promise<void> => {
  try {
    console.log("ğŸ—‘ï¸ Attempting to delete image:", imageUrl);
    
    // Check if this is a Supabase storage URL
    if (!imageUrl.includes('/storage/v1/object/public/inspection-images/') && !imageUrl.includes('inspection-images/')) {
      console.log("â­ï¸ Not a Supabase storage URL, skipping deletion");
      return;
    }
    
    // Extract the path from the URL
    const urlPath = new URL(imageUrl).pathname;
    const pathParts = urlPath.split('/');
    const bucketIndex = pathParts.indexOf('inspection-images');
    
    if (bucketIndex === -1) {
      console.log("âŒ Could not find bucket name in URL:", imageUrl);
      return;
    }
    
    const fileName = pathParts.slice(bucketIndex + 1).join('/');
    
    if (!fileName) {
      console.log("âŒ Could not extract file path from URL:", imageUrl);
      return;
    }
    
    console.log("ğŸ—‘ï¸ Deleting file:", fileName);
    
    // Delete from storage
    const { error } = await supabase.storage
      .from('inspection-images')
      .remove([fileName]);
    
    if (error) {
      console.error("âŒ Error deleting image from storage:", error);
    } else {
      console.log("âœ… Image deleted successfully from storage:", fileName);
    }
  } catch (error) {
    console.error("âŒ Error in deleteReportImage:", error);
  }
};

/**
 * Upload multiple images to Supabase Storage with guaranteed storage
 */
export const uploadMultipleReportImages = async (
  imageUrls: string[],
  reportId: string,
  roomId: string
): Promise<string[]> => {
  try {
    console.log(`ğŸš€ Starting batch upload of ${imageUrls.length} images`);
    
    // Filter only data URLs that need uploading
    const dataUrls = imageUrls.filter(url => url.startsWith('data:'));
    const existingUrls = imageUrls.filter(url => !url.startsWith('data:'));
    
    console.log(`ğŸ“Š Upload breakdown: ${dataUrls.length} new uploads, ${existingUrls.length} existing URLs`);
    
    if (dataUrls.length === 0) {
      console.log("âœ… No new images to upload");
      return imageUrls;
    }
    
    // Upload each image individually and collect results
    const uploadedUrls: string[] = [];
    const failedUploads: string[] = [];
    
    for (let i = 0; i < dataUrls.length; i++) {
      try {
        console.log(`ğŸ“¤ Uploading image ${i + 1}/${dataUrls.length}`);
        const uploadedUrl = await uploadReportImage(dataUrls[i], reportId, roomId);
        uploadedUrls.push(uploadedUrl);
        console.log(`âœ… Image ${i + 1} uploaded successfully`);
      } catch (error) {
        console.error(`âŒ Failed to upload image ${i + 1}:`, error);
        failedUploads.push(dataUrls[i]);
      }
    }
    
    console.log(`ğŸ“Š Upload results: ${uploadedUrls.length} successful, ${failedUploads.length} failed`);
    
    // Combine existing URLs with successfully uploaded URLs
    // For failed uploads, use original data URLs as fallback
    const allUrls = [...existingUrls, ...uploadedUrls, ...failedUploads];
    
    return allUrls;
  } catch (error) {
    console.error("âŒ Error in batch upload:", error);
    // Return original URLs as fallback
    return imageUrls;
  }
};

/**
 * Check if storage bucket exists and is accessible
 */
export const checkStorageBucket = async (): Promise<boolean> => {
  try {
    console.log("ğŸ” Checking storage bucket availability...");
    
    // Since we just created the bucket with the migration, we know it exists
    // But let's still test access to be sure
    try {
      console.log("ğŸ” Testing bucket access permissions...");
      
      // Try to list objects to test access
      const { data: listData, error: listError } = await supabase.storage
        .from('inspection-images')
        .list('', { limit: 1 });
      
      if (listError) {
        console.error("âŒ Storage bucket exists but access denied:", listError);
        return false;
      }
      
      console.log("âœ… Storage bucket accessible and ready for uploads");
      return true;
    } catch (accessError) {
      console.error("âŒ Error testing storage access:", accessError);
      return false;
    }
  } catch (error) {
    console.error("âŒ Error checking storage bucket:", error);
    return false;
  }
};
